#!/usr/bin/env python3
"""
OpenAI TTS CLI Module
Chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ nh giá»ng nÃ³i báº±ng OpenAI TTS API
"""

import os
import argparse
import sys
import asyncio
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any
import json

try:
    from openai import AsyncOpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

try:
    from dotenv import load_dotenv
    load_dotenv()
    HAS_DOTENV = True
except ImportError:
    HAS_DOTENV = False


class OpenAITTSCLI:
    def __init__(self, api_key: Optional[str] = None):
        """Khá»Ÿi táº¡o OpenAI TTS CLI"""
        if not HAS_OPENAI:
            raise ImportError("âŒ Cáº§n cÃ i Ä‘áº·t: pip install openai")
        
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("âŒ Cáº§n cung cáº¥p OPENAI_API_KEY trong biáº¿n mÃ´i trÆ°á»ng hoáº·c tham sá»‘ --api-key")
        
        self.client = AsyncOpenAI(api_key=self.api_key)
        
        # Available models
        self.models = {
            "tts-1": {
                "name": "TTS-1 (Nhanh)",
                "description": "Tá»‘c Ä‘á»™ cao, cháº¥t lÆ°á»£ng tiÃªu chuáº©n",
                "supports_instructions": False
            },
            "tts-1-hd": {
                "name": "TTS-1 HD (Cháº¥t lÆ°á»£ng cao)",
                "description": "Cháº¥t lÆ°á»£ng cao, tá»‘c Ä‘á»™ cháº­m hÆ¡n",
                "supports_instructions": False
            },
            "gpt-4o-mini-tts": {
                "name": "GPT-4o Mini TTS (ThÃ´ng minh)",
                "description": "Model má»›i nháº¥t, há»— trá»£ hÆ°á»›ng dáº«n chi tiáº¿t",
                "supports_instructions": True
            }
        }
        
        # Available voices with descriptions
        self.voices = {
            "alloy": "Giá»ng trung tÃ­nh, cÃ¢n báº±ng",
            "ash": "Giá»ng nam trÆ°á»Ÿng thÃ nh, hÆ¡i tráº§m, phÃ¹ há»£p phim tÃ i liá»‡u",
            "ballad": "Giá»ng ná»¯ má»m máº¡i, áº¥m Ã¡p, phÃ¹ há»£p ná»™i dung tÆ° váº¥n",
            "coral": "Giá»ng ná»¯ tráº», rÃµ rÃ ng, tá»± tin, phÃ¹ há»£p giÃ¡o dá»¥c",
            "echo": "Giá»ng nam tráº», nÄƒng Ä‘á»™ng, phÃ¹ há»£p quáº£ng cÃ¡o",
            "fable": "Giá»ng nam uy tÃ­n, phÃ¹ há»£p thÃ´ng bÃ¡o chÃ­nh thá»©c",
            "nova": "Giá»ng ná»¯ chuyÃªn nghiá»‡p, phÃ¹ há»£p tin tá»©c",
            "onyx": "Giá»ng nam tráº§m, sang trá»ng, phÃ¹ há»£p thuyáº¿t trÃ¬nh",
            "sage": "Giá»ng ná»¯ tá»«ng tráº£i, áº¥m Ã¡p, phÃ¹ há»£p podcast",
            "shimmer": "Giá»ng ná»¯ tÆ°Æ¡i sÃ¡ng, nÄƒng Ä‘á»™ng, phÃ¹ há»£p giáº£i trÃ­"
        }
        
        # Instruction presets for gpt-4o-mini-tts
        self.instruction_presets = {
            "default": "Speak naturally and clearly",
            "cheerful": "Speak in a cheerful and positive tone",
            "professional": "Speak in a professional and authoritative manner",
            "calm": "Speak in a calm and soothing voice",
            "excited": "Speak with enthusiasm and energy",
            "storytelling": "Narrate like telling an engaging story",
            "news": "Read like a news anchor with clarity and authority",
            "podcast": "Speak like a friendly podcast host",
            "meditation": "Speak in a gentle, meditative voice",
            "whisper": "Speak in a soft whisper",
            "dramatic": "Speak dramatically with varying emotions",
            "fast": "Speak at a faster pace with excitement",
            "slow": "Speak slowly and deliberately",
            "educational": "Speak like a teacher explaining concepts clearly"
        }

    async def generate_speech(self, text: str, output_path: str, 
                            model: str = "tts-1", voice: str = "alloy", 
                            speed: float = 1.0, instructions: Optional[str] = None,
                            response_format: str = "mp3") -> bool:
        """Táº¡o speech tá»« text"""
        try:
            print(f"ğŸ¤– Model: {self.models[model]['name']}")
            print(f"ğŸµ Voice: {voice} - {self.voices.get(voice, 'KhÃ´ng cÃ³ mÃ´ táº£')}")
            print(f"âš¡ Speed: {speed}x")
            if instructions and self.models[model]['supports_instructions']:
                print(f"ğŸ“ Instructions: {instructions}")
            print("â³ Äang táº¡o audio...")

            # Prepare parameters
            params = {
                "model": model,
                "input": text,
                "voice": voice,
                "response_format": response_format
            }
            
            # Add speed for non-gpt-4o-mini-tts models
            if not self.models[model]['supports_instructions']:
                params["speed"] = speed
            
            # Add instructions for gpt-4o-mini-tts
            if instructions and self.models[model]['supports_instructions']:
                params["instructions"] = instructions

            # Generate speech
            async with self.client.audio.speech.with_streaming_response.create(**params) as response:
                if response_format == "pcm":
                    # Handle PCM format
                    temp_pcm = output_path + ".pcm"
                    with open(temp_pcm, 'wb') as f:
                        async for chunk in response.iter_bytes():
                            f.write(chunk)
                    
                    # Convert PCM to MP3 using ffmpeg
                    import subprocess
                    result = subprocess.run([
                        "ffmpeg", "-y", "-f", "s16le", "-ar", "24000", "-ac", "1",
                        "-i", temp_pcm, "-acodec", "libmp3lame", "-b:a", "192k", 
                        output_path.replace('.pcm', '.mp3')
                    ], capture_output=True)
                    
                    os.remove(temp_pcm)
                    if result.returncode != 0:
                        print(f"âŒ Lá»—i chuyá»ƒn Ä‘á»•i PCM: {result.stderr.decode()}")
                        return False
                    
                    output_path = output_path.replace('.pcm', '.mp3')
                else:
                    # Handle other formats (mp3, wav, etc.)
                    with open(output_path, 'wb') as f:
                        async for chunk in response.iter_bytes():
                            f.write(chunk)

            file_size = os.path.getsize(output_path) / (1024 * 1024)
            print(f"âœ… Táº¡o thÃ nh cÃ´ng: {output_path} ({file_size:.2f} MB)")
            return True

        except Exception as e:
            print(f"âŒ Lá»—i: {str(e)}")
            return False

    async def preview_speech(self, text: str, model: str = "tts-1", 
                           voice: str = "alloy", instructions: Optional[str] = None) -> Optional[bytes]:
        """Táº¡o preview ngáº¯n Ä‘á»ƒ test voice"""
        try:
            # Limit preview text
            preview_text = text[:200] + "..." if len(text) > 200 else text
            
            params = {
                "model": model,
                "input": preview_text,
                "voice": voice,
                "response_format": "mp3"
            }
            
            if instructions and self.models[model]['supports_instructions']:
                params["instructions"] = instructions
            else:
                params["speed"] = 1.0

            async with self.client.audio.speech.with_streaming_response.create(**params) as response:
                audio_data = b""
                async for chunk in response.iter_bytes():
                    audio_data += chunk
                return audio_data

        except Exception as e:
            print(f"âŒ Lá»—i preview: {str(e)}")
            return None

    async def batch_generate(self, texts: List[str], output_dir: str, 
                           model: str = "tts-1", voice: str = "alloy",
                           speed: float = 1.0, instructions: Optional[str] = None,
                           prefix: str = "tts") -> List[str]:
        """Táº¡o nhiá»u file audio cÃ¹ng lÃºc"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        successful_files = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        print(f"ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ {len(texts)} Ä‘oáº¡n vÄƒn báº£n...")
        
        for i, text in enumerate(texts, 1):
            output_file = output_dir / f"{prefix}_{timestamp}_{i:03d}.mp3"
            print(f"\nğŸ“ Xá»­ lÃ½ {i}/{len(texts)}: {text[:50]}...")
            
            success = await self.generate_speech(
                text=text,
                output_path=str(output_file),
                model=model,
                voice=voice,
                speed=speed,
                instructions=instructions
            )
            
            if success:
                successful_files.append(str(output_file))
            else:
                print(f"âŒ Tháº¥t báº¡i: {i}/{len(texts)}")
        
        print(f"\nâœ… HoÃ n thÃ nh: {len(successful_files)}/{len(texts)} file thÃ nh cÃ´ng")
        return successful_files

    def create_output_filename(self, prefix: str = "openai_tts", extension: str = "mp3") -> str:
        """Táº¡o tÃªn file output vá»›i timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}.{extension}"

    def list_models(self):
        """Hiá»ƒn thá»‹ danh sÃ¡ch models"""
        print("ğŸ¤– Danh sÃ¡ch OpenAI TTS Models:")
        for model_id, info in self.models.items():
            print(f"  {model_id}")
            print(f"    -> {info['name']}")
            print(f"    -> {info['description']}")
            print(f"    -> Há»— trá»£ instructions: {'CÃ³' if info['supports_instructions'] else 'KhÃ´ng'}")
            print()

    def list_voices(self):
        """Hiá»ƒn thá»‹ danh sÃ¡ch voices"""
        print("ğŸµ Danh sÃ¡ch OpenAI TTS Voices:")
        for voice, description in self.voices.items():
            print(f"  {voice:10s} - {description}")

    def list_instructions(self):
        """Hiá»ƒn thá»‹ danh sÃ¡ch instruction presets"""
        print("ğŸ“ Danh sÃ¡ch Instruction Presets (chá»‰ cho gpt-4o-mini-tts):")
        for preset, instruction in self.instruction_presets.items():
            print(f"  {preset:15s} - {instruction}")

    async def interactive_mode(self):
        """Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c"""
        print("ğŸ™ï¸ Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c OpenAI TTS (gÃµ 'quit' Ä‘á»ƒ thoÃ¡t)")
        
        # Default settings
        current_model = "tts-1"
        current_voice = "alloy"
        current_speed = 1.0
        current_instructions = None
        
        while True:
            print(f"\nâš™ï¸ CÃ i Ä‘áº·t hiá»‡n táº¡i: Model={current_model}, Voice={current_voice}, Speed={current_speed}x")
            if current_instructions:
                print(f"ğŸ“ Instructions: {current_instructions}")
            
            command = input("\nğŸ’¬ Nháº­p lá»‡nh (text/set/help/quit): ").strip()
            
            if command.lower() == 'quit':
                break
            elif command.lower() == 'help':
                print("""
Lá»‡nh cÃ³ sáºµn:
  text <vÄƒn báº£n>     - Táº¡o TTS tá»« vÄƒn báº£n
  set model <model>  - Äá»•i model
  set voice <voice>  - Äá»•i voice  
  set speed <speed>  - Äá»•i tá»‘c Ä‘á»™
  set instructions <text> - Äáº·t hÆ°á»›ng dáº«n (chá»‰ gpt-4o-mini-tts)
  models            - Hiá»ƒn thá»‹ danh sÃ¡ch models
  voices            - Hiá»ƒn thá»‹ danh sÃ¡ch voices
  instructions      - Hiá»ƒn thá»‹ presets instructions
  quit              - ThoÃ¡t
                """)
            elif command.startswith('set '):
                parts = command.split(' ', 2)
                if len(parts) >= 3:
                    setting, value = parts[1], parts[2]
                    if setting == 'model' and value in self.models:
                        current_model = value
                        print(f"âœ… ÄÃ£ Ä‘á»•i model: {value}")
                    elif setting == 'voice' and value in self.voices:
                        current_voice = value
                        print(f"âœ… ÄÃ£ Ä‘á»•i voice: {value}")
                    elif setting == 'speed':
                        try:
                            speed = float(value)
                            if 0.25 <= speed <= 4.0:
                                current_speed = speed
                                print(f"âœ… ÄÃ£ Ä‘á»•i speed: {speed}x")
                            else:
                                print("âŒ Speed pháº£i tá»« 0.25 Ä‘áº¿n 4.0")
                        except:
                            print("âŒ Speed khÃ´ng há»£p lá»‡")
                    elif setting == 'instructions':
                        if self.models[current_model]['supports_instructions']:
                            current_instructions = value
                            print(f"âœ… ÄÃ£ Ä‘áº·t instructions: {value}")
                        else:
                            print(f"âŒ Model {current_model} khÃ´ng há»— trá»£ instructions")
                    else:
                        print("âŒ CÃ i Ä‘áº·t khÃ´ng há»£p lá»‡")
                else:
                    print("âŒ Lá»‡nh set cáº§n Ä‘á»§ tham sá»‘")
            elif command == 'models':
                self.list_models()
            elif command == 'voices':
                self.list_voices()
            elif command == 'instructions':
                self.list_instructions()
            elif command.startswith('text '):
                text = command[5:]
                if text:
                    output_file = self.create_output_filename()
                    success = await self.generate_speech(
                        text=text,
                        output_path=output_file,
                        model=current_model,
                        voice=current_voice,
                        speed=current_speed,
                        instructions=current_instructions
                    )
                    if success:
                        print(f"ğŸµ File Ä‘Ã£ lÆ°u: {output_file}")
                else:
                    print("âŒ Cáº§n nháº­p vÄƒn báº£n")
            else:
                print("âŒ Lá»‡nh khÃ´ng há»£p lá»‡. GÃµ 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n")


async def main():
    parser = argparse.ArgumentParser(
        description="ğŸ™ï¸ OpenAI TTS CLI - Chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ nh giá»ng nÃ³i",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  # TTS cÆ¡ báº£n
  python openai_tts.py "Xin chÃ o tháº¿ giá»›i"
  
  # TTS vá»›i voice vÃ  model cá»¥ thá»ƒ
  python openai_tts.py "Tin tá»©c hÃ´m nay" --voice nova --model tts-1-hd
  
  # TTS vá»›i instructions (chá»‰ gpt-4o-mini-tts)
  python openai_tts.py "ChÃ o má»«ng" --model gpt-4o-mini-tts --instructions "Speak cheerfully"
  
  # Äá»c tá»« file
  python openai_tts.py --input script.txt --output audio.mp3 --voice coral
  
  # Batch processing
  python openai_tts.py --batch texts.json --output-dir ./output
  
  # Preview voice
  python openai_tts.py "Test voice" --preview --voice shimmer
  
  # Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c
  python openai_tts.py --interactive
        """
    )

    # Global arguments
    parser.add_argument('text', nargs='?', help='VÄƒn báº£n cáº§n chuyá»ƒn Ä‘á»•i')
    parser.add_argument('--api-key', help='OpenAI API key (hoáº·c dÃ¹ng biáº¿n mÃ´i trÆ°á»ng OPENAI_API_KEY)')
    parser.add_argument('--input', '-i', help='File vÄƒn báº£n input')
    parser.add_argument('--output', '-o', help='File audio output')
    parser.add_argument('--batch', help='File JSON chá»©a danh sÃ¡ch vÄƒn báº£n Ä‘á»ƒ xá»­ lÃ½ hÃ ng loáº¡t')
    parser.add_argument('--output-dir', help='ThÆ° má»¥c output cho batch processing', default='./output')
    
    # Model and voice settings
    parser.add_argument('--model', '-m', default='tts-1', 
                       choices=['tts-1', 'tts-1-hd', 'gpt-4o-mini-tts'],
                       help='Model TTS (máº·c Ä‘á»‹nh: tts-1)')
    parser.add_argument('--voice', '-v', default='alloy',
                       choices=['alloy', 'ash', 'ballad', 'coral', 'echo', 'fable', 'nova', 'onyx', 'sage', 'shimmer'],
                       help='Voice (máº·c Ä‘á»‹nh: alloy)')
    parser.add_argument('--speed', '-s', type=float, default=1.0, 
                       help='Tá»‘c Ä‘á»™ Ä‘á»c 0.25-4.0 (máº·c Ä‘á»‹nh: 1.0, chá»‰ cho tts-1/tts-1-hd)')
    parser.add_argument('--instructions', help='HÆ°á»›ng dáº«n giá»ng Ä‘iá»‡u (chá»‰ cho gpt-4o-mini-tts)')
    parser.add_argument('--preset-instructions', choices=list(OpenAITTSCLI({}).instruction_presets.keys()),
                       help='Preset instructions cÃ³ sáºµn')
    parser.add_argument('--response-format', default='mp3', choices=['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'],
                       help='Äá»‹nh dáº¡ng audio output (máº·c Ä‘á»‹nh: mp3)')
    
    # Utility arguments
    parser.add_argument('--preview', action='store_true', help='Chá»‰ táº¡o preview ngáº¯n Ä‘á»ƒ test')
    parser.add_argument('--interactive', action='store_true', help='Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c')
    parser.add_argument('--list-models', action='store_true', help='Hiá»ƒn thá»‹ danh sÃ¡ch models')
    parser.add_argument('--list-voices', action='store_true', help='Hiá»ƒn thá»‹ danh sÃ¡ch voices')
    parser.add_argument('--list-instructions', action='store_true', help='Hiá»ƒn thá»‹ danh sÃ¡ch instruction presets')

    args = parser.parse_args()

    try:
        # Initialize TTS client - pass empty dict if no api_key to avoid error in __init__
        if args.api_key or os.getenv('OPENAI_API_KEY'):
            tts = OpenAITTSCLI(api_key=args.api_key)
        else:
            # Just for listing info, don't need API key
            if args.list_models or args.list_voices or args.list_instructions:
                tts = type('MockTTS', (), {})()
                tts.models = OpenAITTSCLI.__dict__['__init__'].__defaults__[0] if hasattr(OpenAITTSCLI.__dict__['__init__'], '__defaults__') else OpenAITTSCLI({'dummy': 'key'}).models
                tts.voices = OpenAITTSCLI({'dummy': 'key'}).voices
                tts.instruction_presets = OpenAITTSCLI({'dummy': 'key'}).instruction_presets
                tts.list_models = lambda: OpenAITTSCLI({'dummy': 'key'}).list_models()
                tts.list_voices = lambda: OpenAITTSCLI({'dummy': 'key'}).list_voices()
                tts.list_instructions = lambda: OpenAITTSCLI({'dummy': 'key'}).list_instructions()
            else:
                tts = OpenAITTSCLI(api_key=args.api_key)
        
        # Handle list commands
        if args.list_models:
            tts.list_models()
            return
        
        if args.list_voices:
            tts.list_voices()
            return
            
        if args.list_instructions:
            tts.list_instructions()
            return

        # Interactive mode
        if args.interactive:
            await tts.interactive_mode()
            return

        # Validate speed
        if not (0.25 <= args.speed <= 4.0):
            print("âŒ Speed pháº£i tá»« 0.25 Ä‘áº¿n 4.0")
            return

        # Handle instructions
        instructions = None
        if args.preset_instructions:
            instructions = tts.instruction_presets[args.preset_instructions]
        elif args.instructions:
            instructions = args.instructions

        # Validate instructions usage
        if instructions and not tts.models[args.model]['supports_instructions']:
            print(f"âŒ Model {args.model} khÃ´ng há»— trá»£ instructions. Chá»‰ gpt-4o-mini-tts má»›i há»— trá»£.")
            return

        # Get text input
        text = None
        if args.batch:
            # Batch processing
            if not Path(args.batch).exists():
                print(f"âŒ File batch khÃ´ng tá»“n táº¡i: {args.batch}")
                return
            
            try:
                with open(args.batch, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        texts = data
                    elif isinstance(data, dict) and 'texts' in data:
                        texts = data['texts']
                    else:
                        print("âŒ File JSON pháº£i chá»©a array hoáº·c object vá»›i key 'texts'")
                        return
                
                successful_files = await tts.batch_generate(
                    texts=texts,
                    output_dir=args.output_dir,
                    model=args.model,
                    voice=args.voice,
                    speed=args.speed,
                    instructions=instructions
                )
                
                print(f"\nğŸ‰ Batch processing hoÃ n táº¥t!")
                print(f"ğŸ“ ThÆ° má»¥c output: {args.output_dir}")
                return
                
            except json.JSONDecodeError:
                print("âŒ File JSON khÃ´ng há»£p lá»‡")
                return
            except Exception as e:
                print(f"âŒ Lá»—i xá»­ lÃ½ batch: {str(e)}")
                return

        elif args.input:
            if not Path(args.input).exists():
                print(f"âŒ File khÃ´ng tá»“n táº¡i: {args.input}")
                return
            with open(args.input, 'r', encoding='utf-8') as f:
                text = f.read().strip()
        elif args.text:
            text = args.text
        else:
            print("âŒ Cáº§n cung cáº¥p vÄƒn báº£n qua tham sá»‘, --input, hoáº·c --batch")
            return

        if not text:
            print("âŒ VÄƒn báº£n trá»‘ng")
            return

        # Preview mode
        if args.preview:
            print("ğŸ”Š Táº¡o preview...")
            audio_data = await tts.preview_speech(
                text=text,
                model=args.model,
                voice=args.voice,
                instructions=instructions
            )
            if audio_data:
                preview_file = f"preview_{datetime.now().strftime('%H%M%S')}.mp3"
                with open(preview_file, 'wb') as f:
                    f.write(audio_data)
                print(f"âœ… Preview Ä‘Ã£ lÆ°u: {preview_file}")
                
                # Optional: play preview if available
                try:
                    import subprocess
                    import platform
                    system = platform.system()
                    if system == "Darwin":  # macOS
                        subprocess.run(["afplay", preview_file])
                    elif system == "Windows":
                        subprocess.run(["start", preview_file], shell=True)
                    elif system == "Linux":
                        subprocess.run(["xdg-open", preview_file])
                except:
                    pass
            return

        # Generate speech
        output_file = args.output or tts.create_output_filename()
        
        # Add extension if not present
        if not Path(output_file).suffix:
            output_file = f"{output_file}.{args.response_format}"

        success = await tts.generate_speech(
            text=text,
            output_path=output_file,
            model=args.model,
            voice=args.voice,
            speed=args.speed,
            instructions=instructions,
            response_format=args.response_format
        )

        if success:
            print(f"ğŸµ File Ä‘Ã£ lÆ°u: {output_file}")
        else:
            print("âŒ Táº¡o TTS tháº¥t báº¡i")
            sys.exit(1)

    except ValueError as e:
        print(str(e))
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ÄÃ£ há»§y bá»")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng mong muá»‘n: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
